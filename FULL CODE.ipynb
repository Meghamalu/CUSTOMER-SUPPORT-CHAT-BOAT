{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kBpPs58_JgD3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import spacy\n",
        "import random\n",
        "from spacy.util import minibatch, compounding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "import joblib\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-mWTDKVJjvi",
        "outputId": "1736ad24-333e-4840-f478-342b14990c40"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/customerchatboat/data.csv')"
      ],
      "metadata": {
        "id": "ynw-SsIbJj76"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H42m1hZWLhOf",
        "outputId": "8bb8a668-8eec-4482-8523-2d33db54535e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   flags                                        instruction category  \\\n",
            "0      B   question about cancelling order {{Order Number}}    ORDER   \n",
            "1    BQZ  i have a question about cancelling oorder {{Or...    ORDER   \n",
            "2   BLQZ    i need help cancelling puchase {{Order Number}}    ORDER   \n",
            "3     BL         I need to cancel purchase {{Order Number}}    ORDER   \n",
            "4  BCELN  I cannot afford this order, cancel purchase {{...    ORDER   \n",
            "\n",
            "         intent                                           response  \n",
            "0  cancel_order  I've understood you have a question regarding ...  \n",
            "1  cancel_order  I've been informed that you have a question ab...  \n",
            "2  cancel_order  I can sense that you're seeking assistance wit...  \n",
            "3  cancel_order  I understood that you need assistance with can...  \n",
            "4  cancel_order  I'm sensitive to the fact that you're facing f...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Split the data into features and labels for intent recognition\n",
        "X_intent = df['instruction']  # Features\n",
        "y_intent = df['intent']  # Labels\n",
        "\n",
        "# Split the data into training and testing sets for intent recognition\n",
        "X_train_intent, X_test_intent, y_train_intent, y_test_intent = train_test_split(X_intent, y_intent, test_size=0.2, random_state=42)\n",
        "\n",
        "# TF-IDF vectorization for intent recognition\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_intent)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test_intent)\n",
        "\n",
        "# Train a Multinomial Naive Bayes classifier for intent recognition\n",
        "intent_classifier = MultinomialNB()\n",
        "intent_classifier.fit(X_train_tfidf, y_train_intent)\n",
        "\n",
        "# Evaluate the classifier for intent recognition\n",
        "y_pred_intent = intent_classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Calculate precision, recall, and F1 score for intent recognition\n",
        "classification_report_intent = classification_report(y_test_intent, y_pred_intent)\n",
        "print(\"Intent Recognition Model Evaluation:\")\n",
        "print(classification_report_intent)\n",
        "\n",
        "# Load spaCy's NER model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Define a function to extract entities from text\n",
        "def extract_entities(text):\n",
        "    doc = nlp(text)\n",
        "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "    return entities\n",
        "\n",
        "# Extract entities from each instruction\n",
        "df['entities'] = df['instruction'].apply(extract_entities)\n",
        "\n",
        "# Define a conversation context dictionary to store slot values\n",
        "conversation_context = {}\n",
        "\n",
        "# Define a function to fill slots based on recognized intents and extracted entities\n",
        "def fill_slots(intent, entities):\n",
        "    global conversation_context\n",
        "    if intent == 'cancel_order':\n",
        "        for entity, label in entities:\n",
        "            if label == 'Order Number':\n",
        "                conversation_context['order_number'] = entity\n",
        "    # Add more logic for other intents and entities as needed\n",
        "\n",
        "# Specify the file path where you want to save the DataFrame\n",
        "file_path = '/content/drive/MyDrive/customerchatboat/extraction_results.csv'\n",
        "\n",
        "# Save the DataFrame with entity extraction results to a new CSV file\n",
        "df.to_csv(file_path, index=False)\n",
        "\n",
        "# Display the DataFrame with entity extraction results\n",
        "print(df[['instruction', 'entities']].head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpJ4YaoQc2P6",
        "outputId": "dce602b8-a875-4614-dcc7-bf922e2cd9cb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intent Recognition Model Evaluation:\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "            cancel_order       0.99      1.00      1.00       187\n",
            "            change_order       1.00      1.00      1.00       187\n",
            " change_shipping_address       0.99      0.99      0.99       216\n",
            "  check_cancellation_fee       1.00      1.00      1.00       199\n",
            "           check_invoice       0.99      0.99      0.99       192\n",
            "   check_payment_methods       1.00      1.00      1.00       206\n",
            "     check_refund_policy       0.98      1.00      0.99       200\n",
            "               complaint       1.00      1.00      1.00       203\n",
            "contact_customer_service       1.00      0.99      0.99       208\n",
            "     contact_human_agent       0.99      1.00      0.99       201\n",
            "          create_account       1.00      0.98      0.99       217\n",
            "          delete_account       0.99      0.99      0.99       178\n",
            "        delivery_options       0.99      1.00      0.99       218\n",
            "         delivery_period       0.99      0.99      0.99       171\n",
            "            edit_account       1.00      1.00      1.00       186\n",
            "             get_invoice       0.99      0.99      0.99       215\n",
            "              get_refund       1.00      0.95      0.98       196\n",
            " newsletter_subscription       0.99      1.00      1.00       166\n",
            "           payment_issue       1.00      0.98      0.99       204\n",
            "             place_order       1.00      0.98      0.99       191\n",
            "        recover_password       0.99      1.00      0.99       191\n",
            "   registration_problems       0.98      1.00      0.99       204\n",
            "                  review       1.00      1.00      1.00       224\n",
            " set_up_shipping_address       1.00      1.00      1.00       228\n",
            "          switch_account       0.99      1.00      0.99       184\n",
            "             track_order       0.99      0.99      0.99       198\n",
            "            track_refund       0.98      1.00      0.99       205\n",
            "\n",
            "                accuracy                           0.99      5375\n",
            "               macro avg       0.99      0.99      0.99      5375\n",
            "            weighted avg       0.99      0.99      0.99      5375\n",
            "\n",
            "                                         instruction entities\n",
            "0   question about cancelling order {{Order Number}}       []\n",
            "1  i have a question about cancelling oorder {{Or...       []\n",
            "2    i need help cancelling puchase {{Order Number}}       []\n",
            "3         I need to cancel purchase {{Order Number}}       []\n",
            "4  I cannot afford this order, cancel purchase {{...       []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "import joblib\n",
        "\n",
        "# Create a pipeline with the TF-IDF vectorizer and the intent classifier\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', tfidf_vectorizer),\n",
        "    ('classifier', intent_classifier)\n",
        "])\n",
        "\n",
        "# Specify the file path where you want to save the model\n",
        "file_path = '/content/drive/MyDrive/customerchatboat/intent_classification_model.pkl'\n",
        "\n",
        "# Save the pipeline model\n",
        "joblib.dump(pipeline, file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w292IBNaoOQi",
        "outputId": "4f091e22-caeb-46e9-f9c4-189e79fd2139"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/customerchatboat/intent_classification_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib  # Assuming you used joblib to save the model\n",
        "\n",
        "# Load your trained model for entity extraction\n",
        "model_path = '/content/drive/MyDrive/customerchatboat/intent_classification_model.pkl'\n",
        "model = joblib.load(model_path)\n",
        "\n",
        "# Specify the file path for the dataset\n",
        "dataset_path = '/content/drive/MyDrive/customerchatboat/data.csv'\n",
        "\n",
        "# Load the dataset'\n",
        "\n",
        "dataset = pd.read_csv(dataset_path)\n",
        "\n",
        "# Function to extract entities from text using the model\n",
        "def extract_entities(text):\n",
        "    # Replace this placeholder with your actual entity extraction logic using the model\n",
        "    doc = nlp(text)\n",
        "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "    return entities\n",
        "\n",
        "# Function to retrieve boat information based on the entity mentioned in the question\n",
        "def retrieve_boat_information(entities):\n",
        "    for entity, label in entities:\n",
        "        if label == 'BOAT_ENTITY':\n",
        "            boat_info = boat_data[boat_data['BoatName'] == entity]\n",
        "            if not boat_info.empty:\n",
        "                return boat_info\n",
        "    return None\n",
        "\n",
        "# Function to fetch boat responses based on the intent\n",
        "def get_boat_response(intent):\n",
        "    return dataset[dataset['intent'] == intent]['response'].values[0]\n",
        "\n",
        "while True:\n",
        "    # Get user input\n",
        "    user_question = input(\"Please ask your question: \")\n",
        "\n",
        "    # Extract entities from the user's question using your model\n",
        "    entities = extract_entities(user_question)\n",
        "\n",
        "    # Check if the question mentions any predefined boat entity\n",
        "    boat_info = retrieve_boat_information(entities)\n",
        "\n",
        "    # If boat information is found, provide the answer\n",
        "    if boat_info is not None:\n",
        "        print(\"Here is the information about the boat:\")\n",
        "        print(boat_info)\n",
        "    else:\n",
        "        # Determine intent based on the model (replace this with your actual intent classification logic)\n",
        "        intent = model.predict([user_question])[0]\n",
        "\n",
        "        # Check if the intent is present in the dataset and fetch the boat response\n",
        "        if intent in dataset['intent'].values:\n",
        "            boat_response = get_boat_response(intent)\n",
        "            print(boat_response)\n",
        "        else:\n",
        "            print(\"I'm sorry, but I'm not sure how to respond to that.\")\n",
        "\n",
        "    # Option to stop the loop\n",
        "    stop = input(\"any other qns? (y/n): \")\n",
        "    if stop.lower() != \"y\":\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKM3vRRqR3UC",
        "outputId": "dd23421c-a8cb-426a-d190-63a5acf3dd4a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please ask your question: cancel order\n",
            "I've understood you have a question regarding canceling order {{Order Number}}, and I'm here to provide you with the information you need. Please go ahead and ask your question, and I'll do my best to assist you.\n",
            "any other qns? (y/n): y\n",
            "Please ask your question: ow could I track the compensation?\n",
            "I understand your eagerness to stay updated on the status of your reimbursement. It's completely natural to want to know if there have been any recent updates. Let me quickly check for any new information regarding your reimbursement. Please bear with me for a moment while I gather the details. Your patience is greatly appreciated as we work towards ensuring your satisfaction and resolving any concerns you may have.\n",
            "any other qns? (y/n): n\n"
          ]
        }
      ]
    }
  ]
}